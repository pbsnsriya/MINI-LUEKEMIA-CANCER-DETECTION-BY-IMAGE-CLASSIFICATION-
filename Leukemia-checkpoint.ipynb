{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42643865",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.applications import ResNet50, VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6465248b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read and preprocess images and labels\n",
    "def preprocess_data(data_dir, labels_dir):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for filename in os.listdir(labels_dir):\n",
    "        if filename.endswith('.txt'):\n",
    "            label_file = os.path.join(labels_dir, filename)\n",
    "            with open(label_file, 'r') as file:\n",
    "                for line in file:\n",
    "                    line = line.strip().split()\n",
    "                    image_path = os.path.join(data_dir, line[0])\n",
    "                    image = cv2.imread(image_path)\n",
    "                    image = cv2.resize(image, (224, 224))  # Resize images to 224x224\n",
    "                    label = [float(x) for x in line[1:]]   # Convert label coordinates to float\n",
    "                    labels.append(label)\n",
    "                    images.append(image)\n",
    "    return np.array(images), np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51ed4bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data directories\n",
    "train_images_dir=r'C:\\Users\\pbsns\\OneDrive\\Documents\\cancer\\Leaukemia Detection\\train\\images'\n",
    "train_labels_dir=r'C:\\Users\\pbsns\\OneDrive\\Documents\\cancer\\Leaukemia Detection\\train\\labels'\n",
    "test_images_dir = r'C:\\Users\\pbsns\\OneDrive\\Documents\\cancer\\Leaukemia Detection\\test\\images'\n",
    "test_labels_dir = r'C:\\Users\\pbsns\\OneDrive\\Documents\\cancer\\Leaukemia Detection\\test\\labels'\n",
    "val_images_dir = r'C:\\Users\\pbsns\\OneDrive\\Documents\\cancer\\Leaukemia Detection\\valid\\images'\n",
    "val_labels_dir =  r'C:\\Users\\pbsns\\OneDrive\\Documents\\cancer\\Leaukemia Detection\\valid\\labels'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2e9acc5",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Preprocess data\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m train_images,train_labels\u001b[38;5;241m=\u001b[39mpreprocess_data(train_images_dir, train_labels_dir)\n\u001b[0;32m      3\u001b[0m test_images, test_labels \u001b[38;5;241m=\u001b[39m preprocess_data(test_images_dir, test_labels_dir)\n\u001b[0;32m      4\u001b[0m val_images, val_labels \u001b[38;5;241m=\u001b[39m preprocess_data(val_images_dir, val_labels_dir)\n",
      "Cell \u001b[1;32mIn[2], line 13\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(data_dir, labels_dir)\u001b[0m\n\u001b[0;32m     11\u001b[0m image_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(data_dir, line[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     12\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(image_path)\n\u001b[1;32m---> 13\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mresize(image, (\u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m))  \u001b[38;5;66;03m# Resize images to 224x224\u001b[39;00m\n\u001b[0;32m     14\u001b[0m label \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mfloat\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m line[\u001b[38;5;241m1\u001b[39m:]]   \u001b[38;5;66;03m# Convert label coordinates to float\u001b[39;00m\n\u001b[0;32m     15\u001b[0m labels\u001b[38;5;241m.\u001b[39mappend(label)\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.9.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4152: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Preprocess data\n",
    "train_images,train_labels=preprocess_data(train_images_dir, train_labels_dir)\n",
    "test_images, test_labels = preprocess_data(test_images_dir, test_labels_dir)\n",
    "val_images, val_labels = preprocess_data(val_images_dir, val_labels_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2d7fc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    rotation_range=45,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    zoom_range=0.1,\n",
    "    shear_range=0.1,\n",
    "    brightness_range=[0.5, 1.5],\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b1ff5063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models\n",
    "def build_cnn_model():\n",
    "    model = Sequential([\n",
    "        Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Conv2D(64, (3, 3), activation='relu'),\n",
    "        MaxPooling2D((2, 2)),\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_resnet_model():\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_vgg_model():\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    model = Sequential([\n",
    "        base_model,\n",
    "        Flatten(),\n",
    "        Dense(128, activation='relu'),\n",
    "        Dropout(0.5),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1f77e281",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pbsns\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n"
     ]
    }
   ],
   "source": [
    "# Compile models\n",
    "cnn_model = build_cnn_model()\n",
    "resnet_model = build_resnet_model()\n",
    "vgg_model = build_vgg_model()\n",
    "\n",
    "cnn_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "resnet_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "vgg_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee82b003",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m\n\u001b[0;32m      5\u001b[0m early_stopping \u001b[38;5;241m=\u001b[39m EarlyStopping(monitor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_loss\u001b[39m\u001b[38;5;124m'\u001b[39m, patience\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m----> 7\u001b[0m cnn_history \u001b[38;5;241m=\u001b[39m cnn_model\u001b[38;5;241m.\u001b[39mfit(train_datagen\u001b[38;5;241m.\u001b[39mflow(train_images, train_labels, batch_size\u001b[38;5;241m=\u001b[39mbatch_size),\n\u001b[0;32m      8\u001b[0m                             steps_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_images) \u001b[38;5;241m/\u001b[39m batch_size,\n\u001b[0;32m      9\u001b[0m                             epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m     10\u001b[0m                             validation_data\u001b[38;5;241m=\u001b[39mval_datagen\u001b[38;5;241m.\u001b[39mflow(val_images, val_labels, batch_size\u001b[38;5;241m=\u001b[39mbatch_size),\n\u001b[0;32m     11\u001b[0m                             callbacks\u001b[38;5;241m=\u001b[39m[early_stopping])\n\u001b[0;32m     13\u001b[0m resnet_history \u001b[38;5;241m=\u001b[39m resnet_model\u001b[38;5;241m.\u001b[39mfit(train_datagen\u001b[38;5;241m.\u001b[39mflow(train_images, train_labels, batch_size\u001b[38;5;241m=\u001b[39mbatch_size),\n\u001b[0;32m     14\u001b[0m                                   steps_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_images) \u001b[38;5;241m/\u001b[39m batch_size,\n\u001b[0;32m     15\u001b[0m                                   epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m     16\u001b[0m                                   validation_data\u001b[38;5;241m=\u001b[39mval_datagen\u001b[38;5;241m.\u001b[39mflow(val_images, val_labels, batch_size\u001b[38;5;241m=\u001b[39mbatch_size),\n\u001b[0;32m     17\u001b[0m                                   callbacks\u001b[38;5;241m=\u001b[39m[early_stopping])\n\u001b[0;32m     19\u001b[0m vgg_history \u001b[38;5;241m=\u001b[39m vgg_model\u001b[38;5;241m.\u001b[39mfit(train_datagen\u001b[38;5;241m.\u001b[39mflow(train_images, train_labels, batch_size\u001b[38;5;241m=\u001b[39mbatch_size),\n\u001b[0;32m     20\u001b[0m                             steps_per_epoch\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(train_images) \u001b[38;5;241m/\u001b[39m batch_size,\n\u001b[0;32m     21\u001b[0m                             epochs\u001b[38;5;241m=\u001b[39mepochs,\n\u001b[0;32m     22\u001b[0m                             validation_data\u001b[38;5;241m=\u001b[39mval_datagen\u001b[38;5;241m.\u001b[39mflow(val_images, val_labels, batch_size\u001b[38;5;241m=\u001b[39mbatch_size),\n\u001b[0;32m     23\u001b[0m                             callbacks\u001b[38;5;241m=\u001b[39m[early_stopping])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_images' is not defined"
     ]
    }
   ],
   "source": [
    "# Train models\n",
    "batch_size = 32\n",
    "epochs = 50\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "cnn_history = cnn_model.fit(train_datagen.flow(train_images, train_labels, batch_size=batch_size),\n",
    "                            steps_per_epoch=len(train_images) / batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=val_datagen.flow(val_images, val_labels, batch_size=batch_size),\n",
    "                            callbacks=[early_stopping])\n",
    "\n",
    "resnet_history = resnet_model.fit(train_datagen.flow(train_images, train_labels, batch_size=batch_size),\n",
    "                                  steps_per_epoch=len(train_images) / batch_size,\n",
    "                                  epochs=epochs,\n",
    "                                  validation_data=val_datagen.flow(val_images, val_labels, batch_size=batch_size),\n",
    "                                  callbacks=[early_stopping])\n",
    "\n",
    "vgg_history = vgg_model.fit(train_datagen.flow(train_images, train_labels, batch_size=batch_size),\n",
    "                            steps_per_epoch=len(train_images) / batch_size,\n",
    "                            epochs=epochs,\n",
    "                            validation_data=val_datagen.flow(val_images, val_labels, batch_size=batch_size),\n",
    "                            callbacks=[early_stopping])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61be5298",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Evaluate models\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m cnn_loss, cnn_accuracy \u001b[38;5;241m=\u001b[39m cnn_model\u001b[38;5;241m.\u001b[39mevaluate(test_images, test_labels)\n\u001b[0;32m      3\u001b[0m resnet_loss, resnet_accuracy \u001b[38;5;241m=\u001b[39m resnet_model\u001b[38;5;241m.\u001b[39mevaluate(test_images, test_labels)\n\u001b[0;32m      4\u001b[0m vgg_loss, vgg_accuracy \u001b[38;5;241m=\u001b[39m vgg_model\u001b[38;5;241m.\u001b[39mevaluate(test_images, test_labels)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_images' is not defined"
     ]
    }
   ],
   "source": [
    "# Evaluate models\n",
    "cnn_loss, cnn_accuracy = cnn_model.evaluate(test_images, test_labels)\n",
    "resnet_loss, resnet_accuracy = resnet_model.evaluate(test_images, test_labels)\n",
    "vgg_loss, vgg_accuracy = vgg_model.evaluate(test_images, test_labels)\n",
    "\n",
    "print(\"CNN Test Accuracy:\", cnn_accuracy)\n",
    "print(\"ResNet Test Accuracy:\", resnet_accuracy)\n",
    "print(\"VGG Test Accuracy:\", vgg_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
